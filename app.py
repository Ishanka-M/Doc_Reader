import streamlit as st
import pdfplumber
import pandas as pd
import io
import re

# 1. ‡∂¥‡∑í‡∂ß‡∑î‡∑Ä‡∑ö ‡∂∏‡∑ñ‡∂Ω‡∑í‡∂ö ‡∑É‡∑ê‡∂ö‡∑É‡∑î‡∂∏‡∑ä
st.set_page_config(page_title="Textile Data Extractor", layout="wide")

# GitHub ‡∑Ä‡∑ô‡∂≠‡∑í‡∂±‡∑ä Logo ‡∂ë‡∂ö ‡∂Ω‡∂∂‡∑è‡∂ú‡∂±‡∑ä‡∂±‡∑è Link ‡∂ë‡∂ö
LOGO_URL = "https://raw.githubusercontent.com/Ishanka-M/Doc_Reader/main/logo.png"

# 2. ‡∑Å‡∑ì‡∂ª‡∑ä‡∑Ç‡∂∫ ‡∑É‡∑Ñ Logo ‡∂ë‡∂ö ‡∑É‡∑ê‡∂ö‡∑É‡∑ì‡∂∏
col1, col2 = st.columns([1, 6])
with col1:
    try:
        st.image(LOGO_URL, width=120)
    except:
        st.write("Logo Loading...")

with col2:
    st.title("Bulk Textile Packing List Extractor")

# 3. Reset ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏‡∑ö ‡∂¥‡∑Ñ‡∑É‡∑î‡∂ö‡∂∏ (Session State)
if 'uploader_key' not in st.session_state:
    st.session_state.uploader_key = 0

def reset_app():
    st.session_state.uploader_key += 1
    st.rerun()

# 4. South Asia ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂Ø‡∂≠‡∑ä‡∂≠ ‡∂ö‡∑í‡∂∫‡∑Ä‡∑ì‡∂∏‡∑ö ‡∑Å‡∑ä‚Äç‡∂ª‡∑í‡∂≠‡∂∫
def extract_south_asia(text, file_name):
    rows = []
    shipment_id = re.search(r"Shipment Id\s*:\s*(\d+)", text).group(1) if re.search(r"Shipment Id\s*:\s*(\d+)", text) else "N/A"
    batch_no_main = re.search(r"Batch No\s*:\s*(\d+)", text).group(1) if re.search(r"Batch No\s*:\s*(\d+)", text) else "N/A"
    color = re.search(r"Color Name & No\s*:\s*(.*)", text).group(1) if re.search(r"Color Name & No\s*:\s*(.*)", text) else "N/A"
    f_type = re.search(r"Fabric Type\s*:\s*(.*)", text).group(1) if re.search(r"Fabric Type\s*:\s*(.*)", text) else "N/A"
    
    # ‡∑Ä‡∂ú‡∑î‡∑Ä‡∑ö ‡∂Ø‡∂≠‡∑ä‡∂≠ (Roll #, Lot Batch No, Kg, yd)
    pattern = re.compile(r"(\d{7})\s+([\d\-*]+)\s+(\d+\.\d+)\s+(\d+\.\d+)")
    matches = pattern.findall(text)
    for m in matches:
        rows.append({
            "Source": "SOUTH ASIA",
            "File Name": file_name,
            "Delivery Sheet / Shipment ID": shipment_id,
            "Main Batch No": batch_no_main,
            "Color Name & No": color.strip(),
            "Fabric Type": f_type.strip(),
            "Roll / R No": m[0],
            "Lot Batch No": m[1],
            "Net Weight (Kg)": float(m[2]),
            "Net Length (yd)": float(m[3])
        })
    return rows

# 5. Ocean Lanka ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂Ø‡∂≠‡∑ä‡∂≠ ‡∂ö‡∑í‡∂∫‡∑Ä‡∑ì‡∂∏‡∑ö ‡∑Å‡∑ä‚Äç‡∂ª‡∑í‡∂≠‡∂∫
def extract_ocean_lanka(text, file_name):
    rows = []
    
    # Header ‡∂Ø‡∂≠‡∑ä‡∂≠ ‡∂ö‡∑í‡∂∫‡∑Ä‡∑ì‡∂∏ (Regex ‡∑Ä‡∑ê‡∂©‡∑í‡∂Ø‡∑í‡∂∫‡∑î‡∂´‡∑î ‡∂ö‡∂ª ‡∂á‡∂≠)
    ds_match = re.search(r"Delivery Sheet No\.\s*,\s*\"([A-Z0-9]+)\"", text)
    delivery_sheet = ds_match.group(1) if ds_match else "N/A"
    
    ft_match = re.search(r"Fabric Type\s*\",\s*\"(.*?)\"", text, re.DOTALL)
    fabric_type = ft_match.group(1).replace('\n', ' ').strip() if ft_match else "N/A"
    
    bn_match = re.search(r"Batch No\s*([A-Z0-9]+)", text)
    batch_no = bn_match.group(1) if bn_match else "N/A"
    
    cn_match = re.search(r"Our Colour No\.\s*\n\s*(.*?)\n", text)
    color_no = cn_match.group(1).strip() if cn_match else "N/A"

    # ‡∑Ä‡∂ú‡∑î‡∑Ä‡∑ö ‡∂Ø‡∂≠‡∑ä‡∂≠ ‡∂ö‡∑í‡∂∫‡∑Ä‡∑ì‡∂∏ (R/ No, Net Length, Net Weight)
    # Ocean Lanka ‡∑Ä‡∂ú‡∑î ‡∂¥‡∑ö‡∑Ö‡∑í ‡∂ª‡∂ß‡∑è‡∑Ä: ,"No","Length","Weight"
    pattern = re.compile(r",\s*\"(\d+)\"\s*,\s*\"([\d\.,]+)\"\s*,\s*\"([\d\.,]+)\"")
    matches = pattern.findall(text)
    
    for m in matches:
        length_val = m[1].replace(',', '.')
        weight_val = m[2].replace(',', '.')
        
        rows.append({
            "Source": "OCEAN LANKA",
            "File Name": file_name,
            "Delivery Sheet / Shipment ID": delivery_sheet,
            "Main Batch No": batch_no,
            "Color Name & No": color_no,
            "Fabric Type": fabric_type,
            "Roll / R No": m[0],
            "Lot Batch No": batch_no,
            "Net Weight (Kg)": float(weight_val),
            "Net Length (yd)": float(length_val)
        })
    return rows

# 6. ‡∂¥‡∂ª‡∑í‡∑Å‡∑ì‡∂Ω‡∂ö ‡∂Ö‡∂≠‡∑î‡∂ª‡∑î‡∂∏‡∑î‡∑Ñ‡∑î‡∂´‡∂≠ (UI)
st.markdown("---")
factory_type = st.selectbox("‡∂Ü‡∂∫‡∂≠‡∂±‡∂∫ ‡∂≠‡∑ù‡∂ª‡∂±‡∑ä‡∂± (Select Factory)", ["SOUTH ASIA", "OCEAN LANKA"])

uploaded_files = st.file_uploader(
    f"{factory_type} PDF ‡∂ú‡∑ú‡∂±‡∑î upload ‡∂ö‡∂ª‡∂±‡∑ä‡∂±", 
    type=["pdf"], 
    accept_multiple_files=True, 
    key=f"uploader_{st.session_state.uploader_key}"
)

if st.button("Reset All"):
    reset_app()

if uploaded_files:
    all_extracted_data = []
    with st.spinner("‡∂Ø‡∂≠‡∑ä‡∂≠ ‡∂ö‡∑í‡∂∫‡∑Ä‡∂∏‡∑í‡∂±‡∑ä ‡∂¥‡∑Ä‡∂≠‡∑ì..."):
        for file in uploaded_files:
            with pdfplumber.open(file) as pdf:
                full_text = ""
                for page in pdf.pages:
                    full_text += page.extract_text() + "\n"
                
                if factory_type == "SOUTH ASIA":
                    all_extracted_data.extend(extract_south_asia(full_text, file.name))
                else:
                    all_extracted_data.extend(extract_ocean_lanka(full_text, file.name))

    df = pd.DataFrame(all_extracted_data)
    
    if not df.empty:
        st.success(f"‡∂ú‡∑ú‡∂±‡∑î {len(uploaded_files)} ‡∑É‡∑è‡∂ª‡∑ä‡∂Æ‡∂ö‡∑Ä ‡∂ö‡∑í‡∂∫‡∑Ä‡∂± ‡∂Ω‡∂Ø‡∑ì.")
        st.dataframe(df, use_container_width=True)

        # Excel Download
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, index=False)
        
        st.download_button(
            label="üì• Download Excel File",
            data=output.getvalue(),
            file_name=f"{factory_type}_Data.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    else:
        st.error("‡∂Ø‡∂≠‡∑ä‡∂≠ ‡∑Ñ‡∂≥‡∑î‡∂±‡∑è ‡∂ú‡∑ê‡∂±‡∑ì‡∂∏‡∂ß ‡∂±‡∑ú‡∑Ñ‡∑ê‡∂ö‡∑í ‡∑Ä‡∑í‡∂∫. ‡∂ö‡∂ª‡∑î‡∂´‡∑è‡∂ö‡∂ª ‡∂±‡∑í‡∑Ä‡∑ê‡∂ª‡∂Ø‡∑í ‡∂Ü‡∂∫‡∂≠‡∂±‡∂∫ ‡∂≠‡∑ù‡∂ª‡∑è ‡∂á‡∂≠‡∑ä‡∂Ø‡∑ê‡∂∫‡∑í ‡∂¥‡∂ª‡∑ì‡∂ö‡∑ä‡∑Ç‡∑è ‡∂ö‡∂ª‡∂±‡∑ä‡∂±.")

# 7. ‡∂¥‡∑è‡∂Ø‡∂ö‡∂∫ (Footer)
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: gray; font-size: 0.9em;'>"
    "Developed by <b>Ishanka Madusanka</b>"
    "</div>", 
    unsafe_allow_html=True
)
