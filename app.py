import streamlit as st
import pdfplumber
import pandas as pd
import io
import re
import google.generativeai as genai
import json

# --- 1. ‡∂¥‡∑í‡∂ß‡∑î‡∑Ä‡∑ö ‡∂∏‡∑ñ‡∂Ω‡∑í‡∂ö ‡∑É‡∑ê‡∂ö‡∑É‡∑î‡∂∏‡∑ä ‡∑É‡∑Ñ LOGO ---
st.set_page_config(page_title="Textile Data Extractor Pro 2026", layout="wide")

LOGO_URL = "https://raw.githubusercontent.com/Ishanka-M/Doc_Reader/main/logo.png"

col1, col2 = st.columns([1, 6])
with col1:
    try:
        st.image(LOGO_URL, width=120)
    except:
        st.write("Logo Loading...")
with col2:
    st.title("Bulk Textile Packing List Extractor (Gemini 3 Powered)")

st.markdown("---")

# --- 2. API KEY ROTATION LOGIC ---
API_KEYS = st.secrets.get("GEMINI_KEYS", [])

def get_ai_response(prompt):
    """Gemini 3 Pro/Flash ‡∂∏‡∑è‡∂Ø‡∑í‡∂Ω‡∑í ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∂∫‡∑ô‡∂±‡∑ä Keys ‡∂∏‡∑è‡∂ª‡∑î ‡∂ö‡∂ª‡∂∏‡∑í‡∂±‡∑ä ‡∂Ø‡∂≠‡∑ä‡∂≠ ‡∂Ω‡∂∂‡∑è ‡∂ú‡∂±‡∑ì"""
    for key in API_KEYS:
        try:
            genai.configure(api_key=key)
            
            # 2026 ‡∂±‡∑Ä‡∂≠‡∂∏ Gemini 3 Flash ‡∂∏‡∑è‡∂Ø‡∑í‡∂Ω‡∑í‡∂∫ ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏
            # ‡∂∏‡∑ô‡∂∏ ‡∂∏‡∑è‡∂Ø‡∑í‡∂Ω‡∑í‡∂∫ Agentic coding ‡∑É‡∑Ñ Multimodal reasoning ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂â‡∂≠‡∑è ‡∂Ø‡∑í‡∂∫‡∑î‡∂´‡∑î‡∂∫‡∑í
            model = genai.GenerativeModel(
                model_name='gemini-3-flash-preview',
                generation_config={
                    "response_mime_type": "application/json", # ‡∂ö‡∑ô‡∂Ω‡∑í‡∂±‡∑ä‡∂∏ JSON ‡∂Ω‡∂∂‡∑è‡∂ú‡∑ê‡∂±‡∑ì‡∂∏‡∂ß
                }
            )
            
            # ‡∂Ø‡∂≠‡∑ä‡∂≠ ‡∂±‡∑í‡∑É‡∑ä‡∑É‡∑è‡∂ª‡∂´‡∂∫ ‡∑É‡∂≥‡∑Ñ‡∑è Minimal thinking ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏ (‡∑Ä‡∑ö‡∂ú‡∂∫ ‡∑Ä‡∑ê‡∂©‡∑í ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏‡∂ß)
            response = model.generate_content(prompt)
            return response.text
        except Exception as e:
            # ‡∂ë‡∂ö‡∑ä Key ‡∂ë‡∂ö‡∂ö‡∑ä Fail ‡∑Ä‡∑î‡∑Ä‡∑Ñ‡∑ú‡∂≠‡∑ä ‡∂ä‡∑Ö‡∂ü ‡∂ë‡∂ö‡∂ß ‡∂∏‡∑è‡∂ª‡∑î ‡∑Ä‡∑ì‡∂∏
            continue
    return None

# --- 3. SOUTH ASIA EXTRACTION (REGEX) ---
def extract_south_asia(text, file_name):
    rows = []
    ship_id = re.search(r"Shipment Id[\s\n\",:]+(\d+)", text)
    batch_main = re.search(r"Batch No[\s\n\",:]+(\d+)", text)
    color = re.search(r"Color Name & No[\s\n\",:]+(.*?)\n", text)
    f_type = re.search(r"Fabric Type[\s\n\",:]+(.*?)\n", text)

    s_id = ship_id.group(1) if ship_id else "N/A"
    b_no = batch_main.group(1) if batch_main else "N/A"
    c_info = color.group(1).strip() if color else "N/A"
    f_info = f_type.group(1).strip() if f_type else "N/A"

    pattern = re.compile(r"(\d{7})\s+([\d\-*]+)\s+(\d+\.\d+)\s+(\d+\.\d+)")
    matches = pattern.findall(text)
    for m in matches:
        rows.append({
            "Factory Source": "SOUTH ASIA",
            "File Name": file_name,
            "Delivery Sheet / Shipment ID": s_id,
            "Main Batch No": b_no,
            "Color": c_info,
            "Fabric Type": f_info,
            "Roll / R No": m[0],
            "Lot Batch No": m[1],
            "Net Weight (Kg)": float(m[2]),
            "Net Length (yd)": float(m[3])
        })
    return rows

# --- 4. OCEAN LANKA EXTRACTION (GEMINI 3 AI) ---
def extract_ocean_lanka_ai(raw_text, file_name):
    # Gemini 3 ‡∑É‡∂≥‡∑Ñ‡∑è Prompt ‡∂ë‡∂ö (Thinking signatures ‡∑Ä‡∂Ω‡∂ß ‡∂ú‡∑ê‡∂Ω‡∂¥‡∑ô‡∂± ‡∑É‡∑ö)
    prompt = f"""
    Analyze the following Ocean Lanka Packing List text. 
    Return a JSON list of objects containing the following fields:
    - Delivery_Sheet: (e.g. T54090)
    - Fabric_Type: Full description
    - Main_Batch: Batch Number
    - Color: Combine 'Our Colour No.' and 'Heat Setting' into one string
    - Roll_No: R/No
    - Net_Weight: (Kg)
    - Net_Length: (yd)
    
    Raw Text: 
    {raw_text}
    """
    
    ai_res = get_ai_response(prompt)
    rows = []
    
    if ai_res:
        try:
            # Gemini 3 'application/json' MIME type ‡∂ë‡∂ö ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∂ª‡∂± ‡∂±‡∑í‡∑É‡∑è ‡∑É‡∑ò‡∂¢‡∑î‡∑Ä‡∂∏ parse ‡∂ö‡∑Ö ‡∑Ñ‡∑ê‡∂ö
            data = json.loads(ai_res)
            # ‡∂Ø‡∂≠‡∑ä‡∂≠ ‡∂Ω‡∑ê‡∂∫‡∑í‡∑É‡∑ä‡∂≠‡∑î‡∑Ä‡∂ö‡∑ä ‡∂±‡∑ú‡∑Ä‡∂±‡∑ä‡∂±‡∑ö ‡∂±‡∂∏‡∑ä ‡∂ë‡∂∫ ‡∂Ω‡∑ê‡∂∫‡∑í‡∑É‡∑ä‡∂≠‡∑î‡∑Ä‡∂ö‡∑ä ‡∂∂‡∑Ä‡∂ß ‡∂¥‡∂≠‡∑ä ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏
            if isinstance(data, dict) and "table" in data: data = data["table"]
            
            for item in data:
                rows.append({
                    "Factory Source": "OCEAN LANKA",
                    "File Name": file_name,
                    "Delivery Sheet / Shipment ID": item.get("Delivery_Sheet", "N/A"),
                    "Main Batch No": item.get("Main_Batch", "N/A"),
                    "Color": item.get("Color", "N/A"),
                    "Fabric Type": item.get("Fabric_Type", "N/A"),
                    "Roll / R No": item.get("Roll_No", "N/A"),
                    "Lot Batch No": item.get("Main_Batch", "N/A"),
                    "Net Weight (Kg)": item.get("Net_Weight", 0),
                    "Net Length (yd)": item.get("Net_Length", 0)
                })
        except Exception as e:
            st.error(f"Error parsing AI response: {e}")
    return rows

# --- 5. UI - SELECT FACTORY & UPLOAD ---
if 'uploader_key' not in st.session_state:
    st.session_state.uploader_key = 0

factory_type = st.selectbox("‡∂Ü‡∂∫‡∂≠‡∂±‡∂∫ ‡∂≠‡∑ù‡∂ª‡∂±‡∑ä‡∂± (Select Factory)", ["SOUTH ASIA", "OCEAN LANKA"])

uploaded_files = st.file_uploader(
    f"{factory_type} PDF ‡∂ú‡∑ú‡∂±‡∑î upload ‡∂ö‡∂ª‡∂±‡∑ä‡∂±", 
    type=["pdf"], accept_multiple_files=True, 
    key=f"uploader_{st.session_state.uploader_key}"
)

if st.button("Reset All"):
    st.session_state.uploader_key += 1
    st.rerun()

# --- 6. PROCESSING & DOWNLOAD ---

if uploaded_files:
    all_data = []
    with st.spinner(f"Gemini 3 Flash ‡∂∏‡∂ü‡∑í‡∂±‡∑ä {factory_type} ‡∂Ø‡∂≠‡∑ä‡∂≠ ‡∑Ä‡∑í‡∑Å‡∑ä‡∂Ω‡∑ö‡∑Ç‡∂´‡∂∫ ‡∂ö‡∂ª‡∂∫‡∑í..."):
        for file in uploaded_files:
            with pdfplumber.open(file) as pdf:
                full_text = ""
                for page in pdf.pages:
                    full_text += (page.extract_text() or "") + "\n"
                
                if factory_type == "SOUTH ASIA":
                    all_data.extend(extract_south_asia(full_text, file.name))
                else:
                    all_data.extend(extract_ocean_lanka_ai(full_text, file.name))

    if all_data:
        df = pd.DataFrame(all_data)
        st.success(f"‡∂ú‡∑ú‡∂±‡∑î {len(uploaded_files)} ‡∑É‡∑è‡∂ª‡∑ä‡∂Æ‡∂ö‡∑Ä ‡∂ö‡∑í‡∂∫‡∑Ä‡∂± ‡∂Ω‡∂Ø‡∑ì.")
        st.dataframe(df, use_container_width=True)

        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, index=False)
        
        st.download_button(
            label="üì• Download Excel File", data=output.getvalue(),
            file_name=f"{factory_type}_Extracted_Data.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    else:
        st.error("‡∂Ø‡∂≠‡∑ä‡∂≠ ‡∑Ñ‡∂≥‡∑î‡∂±‡∑è ‡∂ú‡∑ê‡∂±‡∑ì‡∂∏‡∂ß ‡∂±‡∑ú‡∑Ñ‡∑ê‡∂ö‡∑í ‡∑Ä‡∑í‡∂∫. ‡∂ö‡∂ª‡∑î‡∂´‡∑è‡∂ö‡∂ª ‡∂±‡∑í‡∑Ä‡∑ê‡∂ª‡∂Ø‡∑í Factory ‡∂ë‡∂ö ‡∂≠‡∑ù‡∂ª‡∑è ‡∂á‡∂≠‡∑ä‡∂Ø‡∑ê‡∂∫‡∑í ‡∂∂‡∂Ω‡∂±‡∑ä‡∂±.")

# --- 7. FOOTER ---
st.markdown("---")
st.markdown("<div style='text-align: center; color: gray;'>Developed by <b>Ishanka Madusanka</b> | Powered by Gemini 3 Flash</div>", unsafe_allow_html=True)
